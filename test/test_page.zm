/******************************************************************************\
FILE:           test_page.zm
AUTHOR:         Theo Veenker (UiL-OTS) <T.J.G.Veenker@uu.nl>
ADAPTED BY:     Martijn van der Klis (UiL-OTS) <M.H.vanderKlis@uu.nl>
                Maarten Duijndam

DESCRIPTION:

Provides a page object to show to the participant during test phase trials.
It handles presenting the stimulus and recording the participant's response.


HISTORY:
2012-11-10 TV   Created.
2013-06-28 MvdK Changed the flow during auditory stimuli for segmentation experiment.
                Added visual randomization.
2013-07-03 MvdK Finalized test page, correct timings, small changes.
2014-03-21 MvdK Removed gaze contingency for familiarization phase.
2017-02-03 MD   Rebuild a lot to allow the presentation of phases.

\******************************************************************************/

color ATTENTION_BACK_COLOR = rgb:BAD6EB; // background color of the attention

enum looking_state {
    STATE_INITIALIZED,
    STATE_LOOKING,
    STATE_NOT_LOOKING
};


Page test_page
{
    TestItem    item;           // trial control parameters
    string      sound;          // current sound file stub
    int         next = 0;       // next familiarization image
    ExpPhase    phase;          // Indicates in which phase we are.
    //bool        etstarted;      // whether or not eye-tracking has started
    dur         sample_dur;     // Duration of a sample

    // Pressing the left button on the button box starts this timer
    // if the timer expires the trial will be aborted.
    Timer abort_trial_timer
    {
        on_event:expire()
        {
            man_response.process_hit(event_time, EVENT_STOP_TIMER);
        }
    }

// Remove
//
//    // If the looking button is pressed this timer is activated from the
//    // attention response. This timer can be canceled when the child
//    // looks away to fast, also from the attention_response.
//    Timer start_trial_timer
//    {
//        on_event:expire()
//        {
//            attention_response.abort();
//
//            time tref = layout.start_stimulus(expire_time + 16.667ms);
//            sound_playback2.abort();
//            auditory_stimulus.start(tref);
//            
//            // start eye tracker
//            eyetracker.target = test_page;
//            eyetracker.start_tracking();
//
//        }
//    }


    init()
    {
        fill_pattern_color = TEST_PAGE_COLOR;
    }

    on_event:message()
    {
        man_response.process_hit(event_time, message_arg);
        attention_response.process_hit(event_time, message_arg);
    }

    on_event:key_press()
    {
        if (eyetracker.handle_key(input_key, input_modifiers)) 
            ;
        else
            handle_special_key(this, input_key, input_modifiers);
    }

    VerticalLayout layout
    {
        init()
        {
            spacing = 50;
            height = 0;         // 0 means as large as possible
        }

        CanvasGadget canvas
        {
            init()
            {
                fill_pattern_color = ATTENTION_BACK_COLOR;
                size = 900, 900;
                offset_x = width / 2;
                offset_y = height / 2;
            }

            on_event:start()
            {
                // Let eye-tracker record eye-movement data. Will stop at end of trial.

                // Print start time to eyetracker data file.
                int dt = int(now() - start_time);
                eyetracker.print_to_data_file("SYNCTIME " + string(dt));
                eyetracker.print_to_data_file(string(dt) + "DISPLAY ON");
            }

            ImageShape attention
            {
                void load(string fn, int w=0)
                {
                    image = fn;

                    width = 500;
                    height= 500;

                    x = -width / 2;
                    y = -height / 2;
                }

                on_event:pre_update()
                {
                    real t = relative_frame * real(display_device.refresh_interval) * 1e-3;
                    rotation = 0.1 * M_PI * sin(2 * M_PI * 0.5 * t);
                }

                on_event:start()
                {
                    // Insane number of repeats, if it would get to this
                    // the experiment would probably be aborted.
                    int num_repeats = 1000;
                    sound_playback2.play(
                        stimuli_dir() + "sounds/" + ATTENTION_SOUND1,
                        stimuli_dir() + "sounds/" + ATTENTION_SOUND2,
                        event_time + 250ms, 250ms,
                        num_repeats
                        );
                    canvas.fill_pattern_color = ATTENTION_BACK_COLOR;
                    control.start_attention_grabber_cross();
                    control.animate_attention_grabber_cross(event_time);
                }

                on_event:finish()
                {
                    sound_playback2.abort();
                    control.clear_attention_grabber_cross();
                }
            }
            
            ImageShape grid
            {
                int  rounded_fps;

                int  last_frame;
                int  nth_frame;

                on_event:init()
                {
                    // center the grid
                    width  =  800;
                    height =  800;
                    x      = -width/2;
                    y      = -height/2;

                    real refresh_rate = display_device.refresh_rate;
                    rounded_fps = int(round(refresh_rate));
                }

                on_event:pre_update()
                {
                    // sometimes pre_update seems to miss a frame
                    // this tries to catch and correct for it.
                    int nframe_advance = relative_frame - last_frame;
                    nth_frame = nth_frame + nframe_advance;
                    last_frame = relative_frame;

                    if (nth_frame >= rounded_fps) {
                        string fn = stimuli_dir() + "images/";
                        fn += get_next_cboard();
                        image = fn;
                        nth_frame -= rounded_fps;
                    }
                }

                on_event:start()
                {
                    auditory_stimulus.play(now());
                    attention.stop(event_time);
                    last_frame = 0;
                    nth_frame  = 0;
                    string fn = get_next_cboard();
                    canvas.fill_pattern_color = TEST_PAGE_COLOR;
                    fn = stimuli_dir() + "images/" + fn;
                }
            }
        }

        time start_attention_getter(time t)
        {
            // Prepare stimulus presentation objects.
            canvas.attention.load(stimuli_dir() + "images/" + ATTENTION_IMAGE);
        
            // Start picture stimulus.
            canvas.attention.start(t, ATTENTION_GETTER_DURATION);

            // Return stimulus onset time.
            return canvas.attention.expected_finish_time;
        }

        // Starts the grid, the eyetracker and the manual and eye response.
        // and the auditory stimuli.
        time start_stimulus(time t)
        {
            // Prepare stimulus presentation objects.
            canvas.grid.image = stimuli_dir() + "images/" + get_next_cboard();

            // Start picture stimulus.
            canvas.grid.start(t);

            // Return stimulus onset time.
            return canvas.grid.expected_start_time;
        }

        void reset()
        {
            full_abort();

            canvas.grid.is_visible = false;
        }
    }

    SoundChain auditory_stimulus
    {
        // Sound source/producer object.
        SoundFile clip {}

        // Sound sink/consumer object.
        SoundPlayback playback {}

        on_event:start()
        {
            eyetracker.print_to_data_file("SOUND ON " + sound);

            control.hide_speaker_icon(FRONT_SIDE | LEFT_SIDE | RIGHT_SIDE);
            control.show_speaker_icon(FRONT_SIDE);
        }

        on_event:finish()
        {
            eyetracker.print_to_data_file("SOUND OFF " + sound);
            
            control.hide_speaker_icon(FRONT_SIDE | LEFT_SIDE | RIGHT_SIDE);
            
            time play_time = finish_time; 
            play_time += interval(phase);

            // terminate the response and trial.
            man_response.process_hit(event_time, EVENT_STOP_TIMER);
        }

        time play(time t)
        {
            // Abort any previous sounds playing.
            abort();
            sound_playback2.abort();

            // Set up sound clip.
            playback.device = sound_output_device;

            // Sound is setup in action
            clip.file = stimuli_dir() + "sounds/" + sound + ".wav";

            // Update status line on control window. Cleared in done() below.
            control.set_status(
                    string(item.type)   + "-"      +
                    string(sound)       + " (id: " +
                    string(item.number) + ")"
                    );
            
            // Start auditory stimulus, return expected start time.
            start(t);
            return expected_start_time;
        }

        dur interval(ExpPhase p) 
        {
            dur ret;
            if(p == FAM_PHASE)
                ret = FAM_INTERSTIMULUS_INTERVAL;
            else 
                ret = INTERSTIMULUS_INTERVAL;
            return ret;
        }
    }

    // Handles the responses from the button box
    Response man_response
    {
        bool    is_looking;
        time    lookstart;
        time    nolookstart;
        dur     cumlt;
        dur     cumnlt;
        int     nlookaways;
        int     nlooks;

        on_event:start()
        {
            clear();
            lookstart = event_time;
            // assume the child is looking.
            is_looking = true;
            // Allow only one of the manual responses to be active.
            attention_response.abort();
        }

        void clear()
        {
            is_looking  = true;
            lookstart   = time(0);
            nolookstart = time(0);
            cumlt       = 0ms;
            cumnlt      = 0ms;
            nlookaways  = 0;
            nlooks      = 1; // The infant is always looking at the start
                             // of the trial.
        }

        void process_hit(time t, int event)
        {
            HitType validity = hit(t);
            
            if (validity == HIT_VALID) {
                if (event == EVENT_STOP_LOOKING) { // start abort timer
                    if (!is_looking)
                        return; // ignore, because we weren't looking.
                    is_looking = false;
                    nolookstart = t;
                    cumlt += (t - lookstart);

                    abort_trial_timer.start(t + MAX_LOOK_AWAY_DURATION);
                    control.stop_clock(t);
                    nlookaways++;
                }
                else if (event == EVENT_START_LOOKING) {
                    if(is_looking)
                        return; // ignore, because we already were looking.
                    is_looking = true;
                    lookstart = t;
                    cumnlt += (t - nolookstart);

                    control.start_clock(t);
                    abort_trial_timer.abort();
                    nlooks++;
                }
                else if (event == EVENT_STOP_TIMER) {
                    // This case aborts 
                    if (is_looking)
                        cumlt += (t - lookstart);
                    else
                        cumnlt+= (t - nolookstart);

                    // Make sure other hits are invalid.
                    ignore_remaining_hits();
                    // stop response for eye_movement
                    eye_response.stop();
                    // abort trial
                    done(CONTINUE);
                }
            }
        }
    }

    Response attention_response
    {
        void process_hit(time t, int event)
        {
            HitType validity = hit(t);

            if (validity == HIT_VALID)
            {
                if (event == EVENT_START_LOOKING)
                {
                    time trialstart = t + ATTEN_STIM_DELAY;

                    time gridon     = layout.start_stimulus(trialstart);
                    // auditory_stimulus.play(gridon); would cancel chime_up and down
                    eyetracker.start_tracking(gridon);
                    man_response.start(gridon);
                    eye_response.start(gridon);
                }
                else if (event == EVENT_STOP_LOOKING)
                {
                    //layout.full_abort();
                    layout.canvas.grid.abort();
                    eyetracker.abort();
                    //auditory_stimulus.abort();
                    man_response.abort();
                    eye_response.abort();
                }
            }
        }
    }

    Response eye_response
    {
        bool    looking;        // true while looking
        time    lookstart;      // looking state start time
        time    nolookstart;    // not-looking state start time
        dur     curlt;          // duration of current looking state
        dur     curnlt;         // duration of current not-looking state

        // Response data.
        dur     cumlt;          // cumulative looking time (duration)
        dur     cumnlt;         // cumulative not-looking time (duration)
        bool    lookedaway;     // if set, infant looked away too long
        int     nlooks;         // num times participant looks at target
        int     nlookaways;     // num times participant looks away from target.

        looking_state  look_state;

        void clear()
        {
            looking     = false;
            lookstart   = time(0);
            nolookstart = time(0);
            curlt       = 0ms;
            curnlt      = 0ms;
            cumlt       = 0ms;
            cumnlt      = 0ms;
            lookedaway  = false;
            look_state  = STATE_INITIALIZED;
            nlooks      = 0;
            nlookaways  = 0;
        }

        void process_hit(time t, bool looking)
        {
            HitType validity = hit(t);
            if (validity == HIT_VALID) {
                if (looking) {
                    if (look_state != STATE_LOOKING) {
                        nlooks++;
                        look_state = STATE_LOOKING;
                    }
                    cumlt += sample_dur;
                }
                else {
                    if (look_state != STATE_NOT_LOOKING) {
                        nlookaways++;
                        look_state = STATE_NOT_LOOKING;
                    }
                    cumnlt += sample_dur;
                }
            }
        }

        void check_gaze(real xeye, real yeye, time t)
        {
            // Passed eye positions are relative to the test window.
            // Make eye coordinates relative to canvas.
            xeye -= layout.canvas.x;
            yeye -= layout.canvas.y;

            if (xeye < 0 || xeye >= layout.canvas.width ||
                yeye < 0 || yeye >= layout.canvas.height
                ) 
                looking = false;
            else
                looking = true;

            process_hit(t, looking);
        }

        on_event:finish()
        {
            eyetracker.stop_tracking();
        }
    }

    // Aborts any ongoing activity on this page and signals the initiator
    // of the trial that we're done.
    void done(int msgid)
    {
        // Just in case; abort presentation if still active.
        layout.reset();
        sound_playback2.abort();
        auditory_stimulus.abort();

        abort_trial_timer.abort();
        control.erase_clock();
        control.hide_speaker_icon(FRONT_SIDE | LEFT_SIDE | RIGHT_SIDE);

        signal_target(msgid);   // tell caller we're done
        target = null;

        control.clear_status();
    }

    // Shows this page (if not yet done) and determines when the trial 
    // should begin. Called from action() below.
    time prepare_trial_start(time tref)
    {
        // Activate the test window so it gets the keyboard focus.
        test_window1.activate();

        // Show this page if not yet shown.
        int alreadyshown = test_window1.show_page(
                this, 
                tref + PAGE_TRANSITION_DELAY,
                PAGE_TRANSITION_DURATION
                );

        // If not yet shown make tref the time it will become fully visible.
        if (!alreadyshown)
            tref = expected_transition_finish_time;

        // First trial should begin FIRST_TRIAL_DELAY from tref. Following
        // trials should begin (FAM_)INTERTRIAL_INTERVAL from tref.
        if (!alreadyshown)
            tref += FIRST_TRIAL_DELAY;
        else {
            if (phase == FAM_PHASE)
                tref += FAM_INTERTRIAL_INTERVAL;
            else
                tref += INTERTRIAL_INTERVAL;
        }

        return tref;
    }

    //==========================================================================

    // Performs preparatory work required before using this page.
    void setup(ExpPhase p)
    {
        sample_dur = eyetracker.sampling_period;
        phase = p;
    }


    // Performs cleaning up if necessary.
    void cleanup()
    {
        layout.reset();
        auditory_stimulus.abort();
        sound_playback2.abort();
    }

    // Starts a trial.
    void action(Object caller,
                TestItem it,
                time tref,
                int count=-1
                )
    {
        // Save passed trial control parameters.
        item = it;
        sound = item.sndfn;

        // Show this page (if necessary) and determine when the trial should begin.
        tref = prepare_trial_start(tref);

        // Reset response data.
        eye_response.clear();
        man_response.clear();

        // Start attention getter in test phase and
        // first trial of familiarization phase.

        layout.start_attention_getter(tref);
        attention_response.start(tref);

        eyetracker.target_page = this;

        // Start visual stimulus at attention getter offet + ATTEN_STIM_DELAY. 
        // Visual stimulus start event procedure will start
        // the audio stimulus and response period.

//        layout.start_stimulus(attenoffset + ATTEN_STIM_DELAY);
//        layout.canvas.grid.load(fn);
//        layout.canvas.grid.start(attenoffset + ATTEN_STIM_DELAY);

        // Enable communication with control window and the clock.
        control.target = this;
//        control.reset_clock();
//        control.begin_clock();
//        control.start_clock(tref);
        
        // Remember who to signal when the trial is over.
        target = caller;
    }
}

