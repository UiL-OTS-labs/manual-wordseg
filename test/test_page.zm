/******************************************************************************\
FILE:           test_page.zm
AUTHOR:         Theo Veenker (UiL-OTS) <T.J.G.Veenker@uu.nl>
ADAPTED BY:     Martijn van der Klis (UiL-OTS) <M.H.vanderKlis@uu.nl>
                Maarten Duijndam

DESCRIPTION:

Provides a page object to show to the participant during test phase trials.
It handles presenting the stimulus and recording the participant's response.


HISTORY:
2012-11-10 TV   Created.
2013-06-28 MvdK Changed the flow during auditory stimuli for segmentation experiment.
                Added visual randomization.
2013-07-03 MvdK Finalized test page, correct timings, small changes.
2014-03-21 MvdK Removed gaze contingency for familiarization phase.
2017-02-03 MD   Rebuild a lot to allow the presentation of phases.

\******************************************************************************/

color ATTENTION_BACK_COLOR = rgb:BAD6EB; // background color of the attention

Page test_page
{
    TestItem    item;           // trial control parameters
    string      sound;          // current sound file stub
    int         next = 0;       // next familiarization image
    ExpPhase    phase;          // Indicates in which phase we are.
    bool        etstarted;      // whether or not eye-tracking has started


    init()
    {
        fill_pattern_color = TEST_PAGE_COLOR;
    }


    on_event:key_press()
    {
        if (eyetracker.handle_key(input_key, input_modifiers)) 
            ;
        else
            handle_special_key(this, input_key, input_modifiers);
    }

    VerticalLayout layout
    {
        init()
        {
            spacing = 50;
            height = 0;         // 0 means as large as possible
        }

        CanvasGadget canvas
        {
            init()
            {
                fill_pattern_color = ATTENTION_BACK_COLOR;
                size = 900, 900;
                offset_x = width / 2;
                offset_y = height / 2;
            }

            on_event:start()
            {
                // Let eye-tracker record eye-movement data. Will stop at end of trial.
                if (!etstarted) { 
                    eyetracker.target_page = test_page;
                    eyetracker.target = test_page;
                    eyetracker.start_tracking();
                    etstarted = true; 
                }

                // Print start time to eyetracker data file.
                int dt = int(now() - start_time);
                eyetracker.print_to_data_file("SYNCTIME " + string(dt));
                eyetracker.print_to_data_file(string(dt) + "DISPLAY ON");

                // Start first auditory stimulus at visual stimulus onset.
                time audonsettime = auditory_stimulus.play(start_time, phase);

                // Enable gaze monitoring at onset of first auditory stimulus.
                response.start(audonsettime);
            }

            ImageShape attention
            {
                void load(string fn, int w=0)
                {
                    image = fn;
                    if (w > 0) {
                        width = w;
                        height = -1;
                    }
                    else {
                        width = 0;
                        height = 0;
                    }
                    x = -actual_width / 2;
                    y = -actual_height / 2;
                }

                on_event:pre_update()
                {
                    real t = relative_frame * real(display_device.refresh_interval) * 1e-3;
                    rotation = 0.1 * M_PI * sin(2 * M_PI * 0.5 * t);
                }

                on_event:start()
                {
                    sound_playback2.play(
                        stimuli_dir() + "sounds/" + ATTENTION_SOUND1,
                        stimuli_dir() + "sounds/" + ATTENTION_SOUND2,
                        event_time + 250ms, 250ms);
                    canvas.fill_pattern_color = ATTENTION_BACK_COLOR;
                }

                on_event:finish()
                {
                    sound_playback2.abort();
                }
            }

//            Timer update_grid
//            {
//                on_event:expire()
//                {
//                    string fn = get_next_cboard();
//                    string new_fn = stimuli_dir() + "images/" + fn;
//                    grid.image = new_fn;
//
//                    start(event_time + 1s);
//                }
//            }

            ImageShape grid
            {
                //void load(string fn, int pos, bool fullsize = false)
                on_event:init()
                {
                    // center the grid
                    width  = 800;
                    height = 800;
                    x      = -width/2;
                    y      = -height/2;
                }

                void load(string fn)
                {
                    image = fn;
                }

                on_event:pre_update()
                {
                    if (relative_frame % 60 == 0) {
                        string fn = stimuli_dir() + "images/";
                        fn += get_next_cboard();
                        load(fn);
                    }
                }

                on_event:start()
                {
                    string fn = get_next_cboard();
                    canvas.fill_pattern_color = TEST_PAGE_COLOR;
                    fn = stimuli_dir() + "images/" + fn;
                }
            }
        }

        time start_attention_getter(time t)
        {
            // Prepare stimulus presentation objects.
            canvas.attention.load(stimuli_dir() + "images/" + ATTENTION_IMAGE);
        
            // Start picture stimulus.
            canvas.attention.start(t, ATTENTION_GETTER_DURATION);

            // Return stimulus onset time.
            return canvas.attention.expected_finish_time;
        }

        time start_stimulus_familiarization(time t)
        {
            // Prepare stimulus presentation objects.
            canvas.grid.load(
                    stimuli_dir() +
                    "images/" +
                    get_next_cboard()
                    ); 

            // Start picture stimulus.
            canvas.start(t);

            // Return stimulus onset time.
            return canvas.expected_start_time;
        }

        time start_stimulus_test(time t)
        {
            // Prepare stimulus presentation objects.
            canvas.grid.load(
                    stimuli_dir() +
                    "images/" +
                    get_next_cboard()
                    ); 

            // Start picture stimulus.
            canvas.start(t);

            // Return stimulus onset time.
            return canvas.expected_start_time;
        }

        void reset()
        {
            full_abort();

            canvas.grid.is_visible = false;
        }
    }

    SoundChain auditory_stimulus
    {
        // Sound source/producer object.
        SoundFile clip {}

        // Sound sink/consumer object.
        SoundPlayback playback {}

        on_event:start()
        {
            eyetracker.print_to_data_file("SOUND ON " + sound); 
        }

        on_event:finish()
        {
            eyetracker.print_to_data_file("SOUND OFF " + sound);
            
            time play_time = finish_time; 
            play_time += interval(phase);

            // MD commented away, don't understand the interval phase
            //response.stop(expected_finish_time + interval(phase));
            response.stop(finish_time);
        }

        time play(time t, ExpPhase p, int index = 0)
        {
            // Abort any previous sounds playing.
            abort();
            sound_playback2.abort();

            // Set up sound clip.
            playback.device = sound_output_device;
            clip.file = stimuli_dir() + "sounds/" + sound + ".wav";

            // Update status line on control window. Cleared in done() below.
            control.set_status(
                    string(item.type)   + "-"      +
                    string(sound)       + " (id: " +
                    string(item.number) + ")"
                    );
            
            // Start auditory stimulus, return expected start time.
            start(t);
            return expected_start_time;
        }

        dur interval(ExpPhase p) 
        {
            dur ret;
            if(p == FAM_PHASE)
                ret = FAM_INTERSTIMULUS_INTERVAL;
            else 
                ret = INTERSTIMULUS_INTERVAL;
            return ret;
        }
    }

    Response response
    {
        bool    looking;        // true while looking
        time    lookstart;      // looking state start time
        time    nolookstart;    // not-looking state start time
        dur     curlt;          // duration of current looking state
        dur     curnlt;         // duration of current not-looking state

        // Response data.
        dur     cumlt;          // cumulative looking time (duration)
        dur     cumnlt;         // cumulative not-looking time (duration)
        bool    lookedaway;     // if set, infant looked away too long

        void clear()
        {
            looking     = false;
            lookstart   = time(0);
            nolookstart = time(0);
            curlt       = 0ms;
            curnlt      = 0ms;
            cumlt       = 0ms;
            cumnlt      = 0ms;
            lookedaway  = false;
        }

        void check_gaze(real xeye, real yeye, time t, bool fixend=false)
        {
            // Passed eye positions are relative to the test window.

            // Make eye coordinates relative to canvas.
            xeye -= layout.canvas.x;
            yeye -= layout.canvas.y;

            if (fixend || 
                    xeye < 0 || xeye >= layout.canvas.width ||
                    yeye < 0 || yeye >= layout.canvas.height
                    ) 
                looking = false;
            else
                looking = true;

            // Evaluate looking during the response period.
            if (looking)
            {
                if (lookstart == time(0)) 
                {
                    cumnlt += curnlt;	
                    curnlt = 0ms;
                    lookstart = t;
                    nolookstart = time(0);
                }
                curlt = t - lookstart;
            }
            else
            {
                if (nolookstart == time(0)) 
                {
                    cumlt += curlt;
                    curlt = 0ms;
                    nolookstart = t;
                    lookstart = time(0);
                }
                curnlt = t - nolookstart;				

                if (MAX_LOOKAWAY_DURATION > 0ms && 
                        curnlt >= MAX_LOOKAWAY_DURATION)
                {
                    lookedaway = true;
                    stop();
                }
            }
        }		

        on_event:finish()
        {
            cumlt   += curlt;
            cumnlt  += curnlt;
            eyetracker.stop_tracking();
            done(CONTINUE);
        }
    }

    // Aborts any ongoing activity on this page and signals the initiator
    // of the trial that we're done.
    void done(int msgid)
    {
        // Just in case; abort presentation if still active.
        layout.reset();
        etstarted = false;
        sound_playback2.abort();
        auditory_stimulus.abort();

        signal_target(msgid);   // tell caller we're done
        target = null;

        control.clear_status();
    }

    // Shows this page (if not yet done) and determines when the trial 
    // should begin. Called from action() below.
    time prepare_trial_start(time tref)
    {
        // Activate the test window so it gets the keyboard focus.
        test_window1.activate();

        // Show this page if not yet shown.
        int alreadyshown = test_window1.show_page(
                this, 
                tref + PAGE_TRANSITION_DELAY,
                PAGE_TRANSITION_DURATION
                );

        // If not yet shown make tref the time it will become fully visible.
        if (!alreadyshown)
            tref = expected_transition_finish_time;

        // First trial should begin FIRST_TRIAL_DELAY from tref. Following
        // trials should begin (FAM_)INTERTRIAL_INTERVAL from tref.
        if (!alreadyshown)
            tref += FIRST_TRIAL_DELAY;
        else {
            if (phase == FAM_PHASE)
                tref += FAM_INTERTRIAL_INTERVAL;
            else
                tref += INTERTRIAL_INTERVAL;
        }

        return tref;
    }

    //==========================================================================

    // Performs preparatory work required before using this page.
    void setup(ExpPhase p)
    {
        phase = p;
    }


    // Performs cleaning up if necessary.
    void cleanup()
    {
        layout.reset();
        auditory_stimulus.abort();
        sound_playback2.abort();
    }

    time action_attention_grabber(time tref)
    {
        return layout.start_attention_getter(tref);
    }

    // Starts a trial.
    void action(Object caller,
                TestItem it,
                time tref,
                bool show_attention,
                int count=-1
                )
    {
        // Save passed trial control parameters.
        item = it;
        sound = item.sndfn;

        // Show this page (if necessary) and determine when the trial should begin.
        tref = prepare_trial_start(tref);

        // Reset response data.
        response.clear();

        // Start attention getter in test phase and
        // first trial of familiarization phase.
        time attenoffset;
        if (show_attention)
            attenoffset = layout.start_attention_getter(tref);
        else 
            attenoffset = tref;

        // Start visual stimulus at attention getter offet + ATTEN_STIM_DELAY. 
        // Visual stimulus start event procedure will start
        // the audio stimulus and response period.
        string fn = stimuli_dir() + "images/" + get_next_cboard();
        if (phase == FAM_PHASE) {
            layout.canvas.start(attenoffset + ATTEN_STIM_DELAY);
            layout.canvas.grid.load(fn);
            layout.canvas.grid.start(attenoffset + ATTEN_STIM_DELAY);
        }
        else {
            layout.start_stimulus_test(attenoffset + ATTEN_STIM_DELAY);
            layout.canvas.grid.load(fn);
            layout.canvas.grid.start(attenoffset + ATTEN_STIM_DELAY);
        }
        
        // Remember who to signal when the trial is over.
        target = caller;
    }
}
